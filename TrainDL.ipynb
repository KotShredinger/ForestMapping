{"cells":[{"cell_type":"code","source":["!pip install geojson\n","!pip install rasterio\n","!pip install pytorch_lightning"],"metadata":{"id":"OfdMhc2tMe2X"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GelFxdkvX5nf"},"outputs":[],"source":["import os\n","import gdal\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import cv2\n","import pandas as pd\n","import rasterio\n","from rasterio.mask import mask as rasterio_mask\n","import geojson\n","import random\n","import argparse\n","from osgeo import gdal\n","from osgeo.gdalconst import GDT_Float32\n","import sys\n","import math\n","import itertools\n","import time\n","import random\n","\n","\n","from sklearn import metrics\n","from sklearn.linear_model import RidgeClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n","from xgboost import XGBClassifier\n","from sklearn.svm import SVC\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.multiclass import OneVsOneClassifier\n","from sklearn.multiclass import OneVsRestClassifier\n","\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torchvision import models\n","\n","import pytorch_lightning as pl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ycxPcmWngal9"},"outputs":[],"source":["def get_img(snapshot):\n","    plt.figure(figsize=(7, 7))\n","    plt.axis(\"off\")\n","    plt.imshow(cv2.merge([snapshot[3], snapshot[2], snapshot[1]]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jPQDkHXuWvwe"},"outputs":[],"source":["def create_df(field_g, field_class, max_canal, num_def_field):\n","    df_def_g = pd.DataFrame(columns=[i for i in range(max_canal)]+['class', 'id'])\n","    for field_i in field_g:\n","        df_def_i = pd.DataFrame(field_i.reshape(max_canal, -1).transpose())\n","        df_def_i['id'] = num_def_field\n","        num_def_field += 1\n","        #df_def_i = df_def_i.loc[(df_def_i[2]>0)&(df_def_i[3]>0)]\n","        df_def_g = pd.concat([df_def_g, df_def_i], ignore_index=True)\n","    df_def_g['class'] = field_class\n","    return df_def_g, num_def_field"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"881nkoAZcvz_"},"outputs":[],"source":["def get_id_test(df_def, part_test, max_shuffle=30):\n","    df_def_count = df_def.groupby('id', as_index=False).count()[['id', 'class']]\n","    max_count = df_def_count['class'].sum()\n","    min_count = 1\n","    min_id_test = []\n","    i_def = 0\n","    while i_def<max_shuffle and abs(min_count-part_test)>0.01:\n","        sum_count = 0\n","        id_test = []\n","        for index_row, df_count_row in df_def_count.sample(frac=1).iterrows():\n","            sum_count += df_count_row['class']\n","            id_test.append(df_count_row['id'])\n","            cur_count = sum_count/max_count\n","            if cur_count>=part_test-0.02:\n","                if abs(cur_count-part_test)<abs(min_count-part_test):\n","                    min_count = cur_count\n","                    min_id_test = id_test\n","                i_def += 1\n","                break\n","    if min_count>part_test*2 or part_test-0.96>0:\n","        min_id_test = []\n","    return min_id_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ANbe4tjA0rE"},"outputs":[],"source":["def create_prepared_df(list_df_def, list_data_def, remove_cloud=True, with_class=False):\n","    df_def = pd.DataFrame()\n","    for data_def, df_i_def in zip(list_data_def, list_df_def):\n","        df_i_def = df_i_def.rename(columns={x:str(x)+'_'+data_def for x in (df_i_def.columns[:-2] if with_class else df_i_def.columns)})\n","        df_def = df_def.join(df_i_def[(df_i_def.columns[:-2] if with_class else df_i_def.columns)], how=\"outer\")\n","    if with_class:\n","        df_def['class'] = df_i_def['class']\n","    if remove_cloud:\n","        for col in df_def.columns[:-1]:\n","            if col.split('_')[0]=='12':\n","                df_def = df_def.loc[df_def[col]<1].reset_index(drop=True)\n","    return df_def"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVyLh0T8IsQf"},"outputs":[],"source":["def kill_max_class(df_def):\n","    df_count = df_def.groupby('class', as_index=False).count()\n","    df_count.index = df_count['class']\n","    class_median = int(df_count[df_count.columns[1]].median())\n","    max_class = df_count[df_count.columns[1]].idxmax()\n","    df_def_max = df_def.loc[df_def['class']==max_class]\n","    df_def_max['ind'] = df_def_max.index\n","    df_def_max = df_def_max.loc[df_def_max['ind'].isin(random.sample(list(df_def_max.index), class_median))]\n","    df_def = pd.concat([df_def.loc[df_def['class']!=max_class], df_def_max[df_def_max.columns[:-1]]], ignore_index=True).sort_values(['class']).reset_index(drop=True)\n","    return df_def"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrZK45aXjp0t"},"outputs":[],"source":["def write_geotiff(raster_input, raster_output, predictions):\n","    \"\"\"\n","    Function to replace values in geotiff upper then threshold by thresholf  ðŸ™‚\n","    \n","    Input : GeoTIFF, threshold_value\n","    \n","    Output : GeoTIFF \n","    \n","    \"\"\"    \n","    in_data, out_data = None, None\n","\n","    # open input raster\n","    in_data = gdal.Open(raster_input)\n","    if in_data is None:\n","        print ('Unable to open %s' % raster_input)\n","        return None\n","\n","    # read in data from first band of input raster\n","    band1 = in_data.GetRasterBand(1)\n","    rows = in_data.RasterYSize\n","    cols = in_data.RasterXSize\n","    vals = band1.ReadAsArray(0, 0, cols, rows)\n","\n","    driver = in_data.GetDriver()\n","    out_data = driver.Create(raster_output, cols, rows, 1, GDT_Float32)\n","\n","    dem_data = np.array(predictions)\n","    out_band = out_data.GetRasterBand(1)\n","    out_band.WriteArray(dem_data)\n","    out_band.FlushCache()\n","    out_band.SetNoDataValue(-32767.)\n","\n","    out_data.SetGeoTransform(in_data.GetGeoTransform())\n","    out_data.SetProjection(in_data.GetProjection())\n","    del out_data\n","    return raster_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HiPKoJc-YooG"},"outputs":[],"source":["path = \"/Forest/data/\"\n","name_field = 'Bratsk'\n","resolution = '10'\n","folder_out = '10'\n","#folder_out = '10_only_forest'\n","\n","path_field = path + name_field + '/' + resolution + '/'\n","path_field_year = [path_field+f+'/' for f in os.listdir(path_field) if f!='Masks']\n","path_snapshots = [field_year+snapshot for field_year in path_field_year for snapshot in os.listdir(field_year)]\n","path_masks = path + name_field + '/' + 'Masks/In/' + os.listdir(path + name_field + '/' + 'Masks/In/')[0]\n","path_out_masks = path + name_field + '/' + 'Masks/Out/' + folder_out + '/'\n","\n","if not os.path.exists(path_out_masks):\n","    os.mkdir(path_out_masks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EVW13GGkxAZz"},"outputs":[],"source":["remove_autumn_months = True\n","if remove_autumn_months:\n","    while [path_snapshot for path_snapshot in path_snapshots if (int(path_snapshot.split('/')[-1].split('.')[0][6:7])<6 or int(path_snapshot.split('/')[-1].split('.')[0][6:7])>8)]:\n","        for path_snapshot in [path_snapshot for path_snapshot in path_snapshots if (int(path_snapshot.split('/')[-1].split('.')[0][6:7])<6 or int(path_snapshot.split('/')[-1].split('.')[0][6:7])>8)]:\n","            path_snapshots.remove(path_snapshot)"]},{"cell_type":"code","source":["count_cloud = float(\"inf\")\n","for path_snapshot in path_snapshots:\n","    if path_snapshot[-9]=='7' or path_snapshot[-9]=='8':\n","        #print(path_snapshot)\n","        field = np.array(gdal.Open(path_snapshot).ReadAsArray())\n","        df_i = pd.DataFrame(field.reshape(13, -1).transpose())\n","        if len(df_i.loc[df_i[12]>0])<count_cloud:\n","            count_cloud = len(df_i.loc[df_i[12]>0])\n","            path_min_cloud = path_snapshot\n","        if count_cloud==0:\n","            print(path_snapshot)\n","            #break"],"metadata":{"id":"46trKkv2QpCd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["field = np.array(gdal.Open(path_min_cloud).ReadAsArray())\n","get_img(field)\n","\n","with open(path_masks) as f:\n","    gj = geojson.load(f)\n","features = [feature[\"geometry\"] for feature in gj['features']]\n","\n","with rasterio.open(path_min_cloud) as src:\n","    out_image, _ = rasterio_mask(src, features, crop=True)\n","\n","get_img(out_image)"],"metadata":{"id":"oiJfHVQmQrZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PnXUfMaxxnpw"},"outputs":[],"source":["def convert_to_geotiff(raster_input, raster_output, values_to_write):\n","    \"\"\"\n","    Save GPP resul geotiff GeoTiff\n","\n","    input: path to geotiff with fPAR \n","    output: path to new geotiff with GPP \n","    values_to_write: np.array with dimensions like input geotiff file\n","\n","    \"\"\"\n","    in_data, out_data = None, None\n","    in_data = gdal.Open(raster_input)\n","    if in_data is None:\n","        print ('Unable to open %s' % raster_input)\n","\n","    # read in data from first band of input raster\n","    band1 = in_data.GetRasterBand(1)\n","    rows = in_data.RasterYSize\n","    cols = in_data.RasterXSize\n","    vals = band1.ReadAsArray(0, 0, cols, rows)\n","\n","    driver = in_data.GetDriver()\n","\n","    num_of_layers = values_to_write.shape[0]\n","\n","    out_data = driver.Create(raster_output, cols, rows, num_of_layers, GDT_Float32)\n","\n","    # Save data\n","    for i in range(num_of_layers):\n","        out_band = out_data.GetRasterBand(i+1)\n","        out_band.WriteArray(values_to_write[i, :, :])\n","    out_band.FlushCache()\n","    out_band.SetNoDataValue(-32767.)\n","\n","    out_data.SetGeoTransform(in_data.GetGeoTransform())\n","    out_data.SetProjection(in_data.GetProjection())\n","    del out_data\n","    return raster_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bnqtK8AucJSf"},"outputs":[],"source":["path_Haralick = '/Forest/HaralickTask_all_part/'\n","path_Haralick_features = [path_Haralick+f+'/' for f in os.listdir(path_Haralick) if f!='tiff']\n","path_Haralick_npy = 'data/BANDS-S2-L2A_HARALICK.npy'"]},{"cell_type":"code","source":["path_terrain = '/Forest/Terrain/'"],"metadata":{"id":"MmE_vK7DMnvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-PZXyTOHckTo"},"outputs":[],"source":["input_raster = path_min_cloud\n","output_raster = path_Haralick+'tiff/'\n","if not os.path.exists(output_raster):\n","    os.mkdir(output_raster)\n","\n","field = np.array(gdal.Open(path_min_cloud).ReadAsArray())\n","Haralick_npy_shape = np.load(path_Haralick_features[0]+'0/'+path_Haralick_npy)[0]\n","for path_Haralick_feature in path_Haralick_features:\n","    if not os.path.exists(output_raster+path_Haralick_feature.split(path_Haralick)[1].split('/')[0]+'.tiff'):\n","        array_reloaded = np.zeros(shape=(field.shape[1], field.shape[2], Haralick_npy_shape.shape[2]))\n","        for i in range(4):\n","            array_reloaded[Haralick_npy_shape.shape[0]*(1-i%2):Haralick_npy_shape.shape[0]*(2-i%2),Haralick_npy_shape.shape[1]*(i//2):Haralick_npy_shape.shape[1]*(i//2+1),:] = np.load(path_Haralick_feature+str(i)+'/'+path_Haralick_npy)[0]\n","        res_fname = convert_to_geotiff(raster_input = input_raster, raster_output=output_raster+path_Haralick_feature.split(path_Haralick)[1].split('/')[0]+'.tiff', values_to_write=array_reloaded.transpose(2, 0, 1))\n","        print(res_fname)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dN82imY11cQX"},"outputs":[],"source":["path_Haralick_tiffs = [output_raster+f for f in os.listdir(output_raster)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JoV0-2RA9AQR"},"outputs":[],"source":["def generate_NDVI(features):\n","    nir = features[7]\n","    red = features[3]\n","    ndvi = (nir-red)/((nir+red).apply(lambda x: 0.000000001 if x==0 else x))\n","    return ndvi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEyjYBbS9ATF"},"outputs":[],"source":["def generate_EVI(features):\n","    evi2 = 2.5*(features[7] - features[3])/((features[7]  + 2.4*features[3] + 1).apply(lambda x: 0.000000001 if x==0 else x))\n","    return evi2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60POICW09hc-"},"outputs":[],"source":["def generate_NDRE(features):\n","    ndre = (features[7] - features[4])/((features[7] + features[4]).apply(lambda x: 0.000000001 if x==0 else x))\n","    return ndre"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qE_jm5W9hfT"},"outputs":[],"source":["def generate_MSAVI(features):\n","    nir = features[7]\n","    red = features[3]\n","    msavi=(2*nir + 1 - ((2*nir+1)**2 - 8*(nir-red))**(1/2))/2\n","    return msavi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNYKfj3-9kJQ"},"outputs":[],"source":["def generate_all_indices(df_def):\n","    df_def_col = list(df_def.columns)\n","    df_def['ndvi'] = generate_NDVI(df_def)\n","    df_def['evi'] = generate_EVI(df_def)\n","    df_def['ndre'] = generate_NDRE(df_def)\n","    df_def['msavi'] = generate_MSAVI(df_def)\n","    df_def = df_def.reindex(columns=df_def_col[:-2]+list(df_def.columns[-4:])+df_def_col[-2:])\n","    return df_def"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwlB-7CtI5yq"},"outputs":[],"source":["def del_row(df_def, create_id_test=False):\n","    del_row_col = []\n","    for col in df_def.columns[:-1]:\n","        if not create_id_test:\n","            if (col[0]=='2' or col[0]=='3') and col[2]=='2':\n","                del_row_col.append(col)\n","        else:\n","            if str(col)[0]=='2' or str(col)[0]=='3':\n","                del_row_col.append(col)\n","    del_row_cond = (df_def[del_row_col[0]]>0)\n","    for col in del_row_col[1:]:\n","        del_row_cond = del_row_cond&(df_def[col]>0)\n","\n","    df_def = df_def.loc[del_row_cond].reset_index(drop=True)\n","    return df_def"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbCBuMPE5wp4"},"outputs":[],"source":["def get_mask(path_field_def, path_masks_def, create_train_test=True, split_test=0.8):\n","    with open(path_masks_def) as f:\n","        gj = geojson.load(f)\n","    features_masks = [feature[\"geometry\"] for feature in gj['features']]\n","    features_ind = [feature[\"properties\"][\"t_Class\"] for feature in gj['features']]\n","    features_ind = [i-3 if i>7 else i for i in features_ind]\n","    if not create_train_test:\n","        mask_data = 0\n","        with rasterio.open(path_field_def) as src:\n","            for i in np.unique(features_ind):\n","                indices_i = [feature_ind for feature_ind, x in enumerate(features_ind) if x == i]\n","                list_masks = [features_masks[index] for index in indices_i]\n","                out_image_full, out_transform = rasterio_mask(src, list_masks)\n","                out_image_full[out_image_full > 0] = i\n","                mask_data += out_image_full\n","        mask_data = mask_data[0,:,:]\n","        return mask_data\n","    else:\n","        mask_data_train = 0\n","        mask_data_test = 0\n","        with rasterio.open(path_field_def) as src:\n","            for i in np.unique(features_ind):\n","                indices_i = [feature_ind for feature_ind, x in enumerate(features_ind) if x == i]\n","                list_masks = [features_masks[index] for index in indices_i]\n","                if len(list_masks)>2:\n","                    patr_i = math.ceil(len(list_masks)*split_test)\n","                    random.shuffle(list_masks)\n","                    list_masks_train = list_masks[:patr_i]\n","                    list_masks_test = list_masks[patr_i:]\n","                    out_image_full, out_transform = rasterio_mask(src, list_masks_train)\n","                    out_image_full[out_image_full > 0] = i\n","                    mask_data_train += out_image_full\n","                    out_image_full, out_transform = rasterio_mask(src, list_masks_test)\n","                    out_image_full[out_image_full > 0] = i\n","                    mask_data_test += out_image_full\n","                else:\n","                    out_image_full, out_transform = rasterio_mask(src, list_masks)\n","                    out_image_full[out_image_full > 0] = i\n","\n","                    mask_i = out_image_full[0].copy()\n","                    mask_i[mask_i > 0] = 1\n","                    mask_arange_i = np.arange(mask_i.shape[0]*mask_i.shape[1]).reshape(mask_i.shape)*mask_i.copy()\n","                    element_i = mask_arange_i.copy().reshape(mask_i.shape[0]*mask_i.shape[1])\n","                    element_i = element_i[element_i != 0]\n","                    element_i = element_i[math.ceil(len(element_i)*split_test)]\n","\n","                    mask_data_train_i = np.zeros(mask_i.shape, dtype=np.uint16)\n","                    mask_data_test_i = np.zeros(mask_i.shape, dtype=np.uint16)\n","                    mask_data_train_i[mask_arange_i<=element_i] = 1\n","                    mask_data_test_i[mask_arange_i>element_i] = 1\n","\n","                    mask_data_train += mask_data_train_i*out_image_full.copy()\n","                    mask_data_test += mask_data_test_i*out_image_full.copy()\n","        mask_data_train = mask_data_train[0,:,:]\n","        mask_data_test = mask_data_test[0,:,:]\n","        return mask_data_train, mask_data_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eewzUMi4gIi7"},"outputs":[],"source":["def get_pixels(a, shape_out):\n","    height = []\n","    width = []\n","    hw = (height, width)\n","    for i_step, i_shape in enumerate(a.shape[1:]):\n","        max_out = math.trunc(i_shape/shape_out)+1\n","        shift_i = (shape_out-i_shape%shape_out)//(i_shape//shape_out)\n","        shift_end = (shape_out-i_shape%shape_out)%(i_shape//shape_out)\n","        for i in range(max_out):\n","            if i!=max_out-1:\n","                hw[i_step].append((shape_out*i-shift_i*i, shape_out*(i+1)-shift_i*i))\n","            else:\n","                hw[i_step].append((shape_out*i-shift_i*i-shift_end, shape_out*(i+1)-shift_i*i-shift_end))\n","    return height, width"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KIDlLTMetyiR"},"outputs":[],"source":["def get_fields_coord(mask_field_def, path_field_def, shape_field, show_def = False):\n","    field_def = np.array(gdal.Open(path_field_def).ReadAsArray())\n","    fields_coord_def = []\n","    non_fields_coord_def = []\n","    height, width = get_pixels(field_def, 96)\n","    for field_coord in [list(x) for x in itertools.product(height, width)]:\n","        if mask_field_def[field_coord[0][0]:field_coord[0][1],field_coord[1][0]:field_coord[1][1]].sum()>0:\n","            fields_coord_def.append(field_coord)\n","        else:\n","            non_fields_coord_def.append(field_coord)\n","    if show_def:\n","        a_def = field_def[9,:,:].copy()\n","        for field_coord in fields_coord_def:\n","            a_def[field_coord[0][0]:field_coord[0][1],field_coord[1][0]:field_coord[1][1]] = field_def[9,field_coord[0][0]:field_coord[0][1],field_coord[1][0]:field_coord[1][1]]+5000\n","        figure, axis = plt.subplots(1, 2, figsize=(10,10))\n","        axis[0].axis(\"off\")\n","        axis[0].imshow(a_def)\n","        a_def = field_def[9,:,:].copy()\n","        for field_coord in non_fields_coord_def:\n","            a_def[field_coord[0][0]:field_coord[0][1],field_coord[1][0]:field_coord[1][1]] = field_def[9,field_coord[0][0]:field_coord[0][1],field_coord[1][0]:field_coord[1][1]]+5000\n","        axis[1].axis(\"off\")\n","        axis[1].imshow(a_def)\n","    return fields_coord_def, non_fields_coord_def"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PEMuYdInlXXX"},"outputs":[],"source":["class ForestDatasetPart(Dataset):\n","\n","    def __init__(self, images_dir, mask_data_Dataset, fields_Dataset, tozero=False):\n","        self.mask_data_Dataset = mask_data_Dataset\n","        self.tozero = tozero\n","        self.images_fields = {}\n","        for i_dir, image_dir in enumerate(images_dir):\n","            for i_field, field_Dataset in enumerate(fields_Dataset):\n","                self.images_fields[i_dir*len(fields_Dataset)+i_field] = (image_dir, field_Dataset)\n","\n","    def __len__(self):\n","        return len(self.images_fields)\n","\n","    def __getitem__(self, idx):\n","        image = np.array(gdal.Open(self.images_fields[idx][0]).ReadAsArray())\n","        field_har = np.array(gdal.Open(path_Haralick_tiffs).ReadAsArray())\n","        field_ter = np.array(gdal.Open(path_terrain).ReadAsArray())\n","        image = np.concatenate((image, field_har), axis=0)\n","        image = np.concatenate((image, field_ter), axis=0)\n","        field_shape = self.images_fields[idx][1]\n","        image = image[:,field_shape[0][0]:field_shape[0][1],field_shape[1][0]:field_shape[1][1]]\n","        labels = self.mask_data_Dataset[field_shape[0][0]:field_shape[0][1],field_shape[1][0]:field_shape[1][1]]\n","\n","        if self.tozero:\n","            labels_ones = labels.copy()\n","            labels_ones[labels_ones > 0] = 1\n","            image = image*labels_ones\n","\n","        image = torch.from_numpy(image.astype(float)).float()\n","        labels = torch.tensor(labels.astype(float)).to(torch.long)\n","        return image, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eWtwS4ShPlxE"},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self,\n","                 n_channels,\n","                 num_classes,\n","                 min_channels=32,\n","                 max_channels=512, \n","                 num_down_blocks=4):\n","        super(UNet, self).__init__()\n","        self.num_classes = num_classes\n","        self.n_channels = n_channels\n","        self.num_down_blocks = num_down_blocks\n","        \n","        # encoder\n","        self.enc_conv1 = nn.Sequential(\n","                                    nn.Conv2d(in_channels=self.n_channels, out_channels=56, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(56),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(in_channels=56, out_channels=112, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(112),\n","                                    nn.ReLU()\n","        )\n","        \n","        self.pool1 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.enc_conv2 = nn.Sequential(\n","                                    nn.Conv2d(in_channels=112, out_channels=224, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(224),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(in_channels=224, out_channels=224, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(224),\n","                                    nn.ReLU()\n","        )\n","        \n","        self.pool2 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.enc_conv3 = nn.Sequential(\n","                                    nn.Conv2d(in_channels=224, out_channels=448, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(448),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(in_channels=448, out_channels=448, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(448),\n","                                    nn.ReLU()\n","        )\n","        \n","        self.pool3 = nn.MaxPool2d(kernel_size=2)\n","        \n","        # bottleneck\n","        self.bottleneck_conv = nn.Sequential(\n","                                    nn.Conv2d(in_channels=448, out_channels=448, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(448),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(in_channels=448, out_channels=448, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(448),\n","                                    nn.ReLU()\n","        )\n","        \n","        # decoder\n","        self.upsample1 = nn.ConvTranspose2d(in_channels=448, out_channels=448, kernel_size=3, stride=2, padding=1,output_padding=1)\n","        \n","        self.dec_conv1 = nn.Sequential(\n","                                    nn.Dropout(p=0.5),\n","                                    nn.Conv2d(in_channels=896, out_channels=224, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(224),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(in_channels=224, out_channels=224, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(224),\n","                                    nn.ReLU()\n","        )\n","        \n","        self.upsample2 = nn.ConvTranspose2d(in_channels=224, out_channels=224, kernel_size=3, stride=2, padding=1,output_padding=1)\n","        \n","        self.dec_conv2 = nn.Sequential(\n","                                    nn.Dropout(p=0.5),\n","                                    nn.Conv2d(in_channels=448, out_channels=112, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(112),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(in_channels=112, out_channels=112, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(112),\n","                                    nn.ReLU()\n","        )\n","        \n","        self.upsample3 = nn.ConvTranspose2d(in_channels=112, out_channels=112, kernel_size=3, stride=2, padding=1,output_padding=1)\n","        \n","        self.dec_conv3 = nn.Sequential(\n","                                    nn.Dropout(p=0.5),\n","                                    nn.Conv2d(in_channels=224, out_channels=112, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(112),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(in_channels=112, out_channels=56, kernel_size=3, padding=1),\n","                                    nn.BatchNorm2d(56),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(in_channels=56, out_channels=self.num_classes, kernel_size=3, padding=1)\n","        )\n","    \n","    def forward(self, inputs):\n","        #print(inputs.shape)\n","        h, w = inputs.shape[2], inputs.shape[3]\n","        pow = 2**self.num_down_blocks\n","        h_near = pow * (h//pow)\n","        w_near = pow * (w//pow)\n","        inputs_near = F.interpolate(inputs, (h_near, w_near))\n","        #print(inputs_near.shape)\n","        # encoder\n","        e1 = self.enc_conv1(inputs_near)\n","        p1 = self.pool1(e1)\n","        e2 = self.enc_conv2(p1)\n","        p2 = self.pool2(e2)\n","        e3 = self.enc_conv3(p2)\n","        p3 = self.pool3(e3)\n","\n","        # bottleneck\n","        b = self.bottleneck_conv(p3)\n","\n","        # decoder\n","        u1 = self.upsample1(b)\n","        c1 = torch.cat([u1, e3], dim=1)\n","        d1 = self.dec_conv1(c1)\n","        u2 = self.upsample2(d1)\n","        c2 = torch.cat([u2, e2], dim=1)\n","        d2 = self.dec_conv2(c2)\n","        u3 = self.upsample3(d2)\n","        c3 = torch.cat([u3, e1], dim=1)\n","        d3 = self.dec_conv3(c3)\n","        logits = F.interpolate(d3, (h, w))\n","\n","        assert logits.shape == (inputs.shape[0], self.num_classes, inputs.shape[2], inputs.shape[3]), 'Wrong shape of the logits'\n","        return logits"]},{"cell_type":"code","source":["class DeepLab(nn.Module):\n","    \"\"\"\n","    Args:\n","      - backbone: ['resnet18', 'vgg11_bn', 'mobilenet_v3_small'],\n","      - aspp: use aspp module\n","      - num classes: num output classes\n","\n","    During forward pass:\n","      - Pass inputs through the backbone to obtain features\n","      - Apply ASPP (if needed)\n","      - Apply head\n","      - Upsample logits back to the shape of the inputs\n","    \"\"\"\n","    def __init__(self, backbone, aspp, num_classes):\n","        super(DeepLab, self).__init__()\n","        self.backbone = backbone\n","        self.init_backbone()\n","        self.num_classes = num_classes\n","        self.aspp_f = aspp\n","\n","        if aspp:\n","            self.aspp = ASPP(self.out_features, 256, [12, 24, 36])\n","\n","        self.head = DeepLabHead(self.out_features, num_classes)\n","\n","    def init_backbone(self):\n","        # TODO: initialize an ImageNet-pretrained backbone\n","        if self.backbone == 'resnet18':\n","            resnet = models.resnet18(pretrained=True).children()\n","            self.resnet = torch.nn.Sequential(\n","                                    *(list(resnet)[:-2])\n","            )\n","            self.out_features = 512\n","\n","        elif self.backbone == 'vgg11_bn':\n","            vgg = models.vgg11_bn(pretrained=True).features\n","            self.vgg = nn.Sequential(\n","                                    *list(vgg)\n","            )\n","            self.out_features = 512\n","\n","        elif self.backbone == 'mobilenet_v3_small':\n","            mobilenet = models.mobilenet_v3_small(pretrained=True).features\n","            self.mobilenet = nn.Sequential(\n","                                    *list(mobilenet)\n","            )\n","            self.out_features = 576\n","\n","    def _forward(self, x):\n","        # TODO: forward pass through the backbone\n","        if self.backbone == 'resnet18':\n","            x = self.resnet(x)\n","\n","        elif self.backbone == 'vgg11_bn':\n","            x = self.vgg(x)\n","\n","        elif self.backbone == 'mobilenet_v3_small':\n","            x = self.mobilenet(x)\n","\n","        return x\n","\n","    def forward(self, inputs):\n","        \n","        #Backbone\n","        inputs_i = self._forward(inputs)\n","        \n","        #ASPP\n","        if self.aspp_f:\n","            inputs_i = self.aspp.forward(inputs_i)\n","            \n","        #DeepLabHead\n","        inputs_i = self.head(inputs_i)\n","        \n","        #Upsample\n","        upsample = nn.Upsample(size = inputs.shape[2:], mode='bilinear')\n","        logits = upsample(inputs_i)\n","\n","        assert logits.shape == (inputs.shape[0], self.num_classes, inputs.shape[2], inputs.shape[3]), 'Wrong shape of the logits'\n","        return logits\n","\n","\n","class DeepLabHead(nn.Sequential):\n","    def __init__(self, in_channels, num_classes):\n","        super(DeepLabHead, self).__init__(\n","            nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(in_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels, num_classes, 1)\n","        )\n","\n","\n","class ASPP(nn.Module):\n","    \"\"\"\n","    Atrous Spatial Pyramid Pooling module\n","    with given atrous_rates and out_channels for each head\n","    Description: https://paperswithcode.com/method/aspp\n","    \n","    Detailed scheme: materials/deeplabv3.png\n","      - \"Rates\" are defined by atrous_rates\n","      - \"Conv\" denotes a Conv-BN-ReLU block\n","      - \"Image pooling\" denotes a global average pooling, followed by a 1x1 \"conv\" block and bilinear upsampling\n","      - The last layer of ASPP block should be Dropout with p = 0.5\n","\n","    Args:\n","      - in_channels: number of input and output channels\n","      - num_channels: number of output channels in each intermediate \"conv\" block\n","      - atrous_rates: a list with dilation values\n","    \"\"\"\n","    def __init__(self, in_channels, num_channels, atrous_rates):\n","        super(ASPP, self).__init__()\n","        \n","        modules = []\n","        \n","        modules.append(nn.Sequential(\n","                                nn.Conv2d(in_channels, num_channels, 1, 1),\n","                                nn.ReLU(),\n","                                nn.BatchNorm2d(num_channels)\n","        ))\n","        \n","        for rate in tuple(atrous_rates):\n","            modules.append(nn.Sequential(\n","                                nn.Conv2d(in_channels, num_channels, 3, 1, padding=rate, dilation=rate),\n","                                nn.BatchNorm2d(num_channels),\n","                                nn.ReLU()\n","            ))\n","        \n","        modules.append(nn.Sequential(\n","                                nn.AdaptiveAvgPool2d((1, 1)),\n","                                nn.Conv2d(in_channels, num_channels, 1, 1)\n","        ))\n","        \n","        self.convs = nn.ModuleList(modules)\n","    \n","        self.conv_out = nn.Conv2d(num_channels * len(self.convs), in_channels, 1, 1)\n","        \n","        self.drop = nn.Dropout(p = 0.5)\n","    \n","    def forward(self, x):\n","        blocks = []\n","        for conv in self.convs:\n","            blocks.append(conv(x))\n","        blocks[-1] = F.upsample(blocks[-1], size=x.shape[2:], mode='bilinear')\n","        \n","        res = torch.cat(blocks, dim=1)\n","        res = self.conv_out(res)\n","        res = self.drop(res)\n","        \n","        assert res.shape[1] == x.shape[1], 'Wrong number of output channels'\n","        assert res.shape[2] == x.shape[2] and res.shape[3] == x.shape[3], 'Wrong spatial size'\n","        return res"],"metadata":{"id":"23JjsxeLP1nD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"58q0bos0A4wC"},"outputs":[],"source":["def calc_val_data(preds, masks, num_classes):\n","    preds = torch.argmax(preds, dim=1)\n","        \n","    intersection = torch.zeros([masks.shape[0], num_classes])\n","    union = torch.zeros([masks.shape[0], num_classes])\n","    target = torch.zeros([masks.shape[0], num_classes])\n","    \n","    for i in range(num_classes):\n","        intersection[:,i] = torch.logical_and(preds == i, masks == i).sum(dim=(1,2))\n","        union[:,i] = torch.logical_or(preds == i, masks == i).sum(dim=(1,2))\n","        target[:,i] = (masks == i).sum(dim=(1,2))\n","    \n","    # Output shapes: B x num_classes\n","\n","    assert isinstance(intersection, torch.Tensor), 'Output should be a tensor'\n","    assert isinstance(union, torch.Tensor), 'Output should be a tensor'\n","    assert isinstance(target, torch.Tensor), 'Output should be a tensor'\n","\n","    assert intersection.shape == union.shape == target.shape, 'Wrong output shape'\n","    assert union.shape[0] == masks.shape[0] and union.shape[1] == num_classes, 'Wrong output shape'\n","\n","    return intersection, union, target\n","\n","def calc_val_loss(intersection, union, target, eps = 1e-7):\n","    mean_iou = torch.mean(intersection/(union+eps))\n","    mean_class_rec = torch.mean(intersection/(target+eps))\n","    mean_acc = torch.sum(intersection)/(torch.sum(target)+eps)\n","\n","    return mean_iou, mean_class_rec, mean_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihQthLzKAts0"},"outputs":[],"source":["class SegModel(pl.LightningModule):\n","    def __init__(\n","        self,\n","        model: str,\n","        backbone: str,\n","        aspp: bool,\n","        augment_data: bool,\n","        optimizer: str,\n","        scheduler: str,\n","        lr: float,\n","        batch_size: int,\n","        data_path: str,\n","        path_field_class: str,\n","        path_mask_class: str,\n","        image_size: int,\n","        num_classes: int,\n","        num_channels: int,\n","        tozero: bool\n","        ):\n","        super(SegModel, self).__init__()\n","        self.num_classes = num_classes\n","\n","        if model == 'unet':\n","            self.net = UNet(num_channels, self.num_classes)\n","        elif model == 'deeplab':\n","            self.net = DeepLab(backbone, aspp, self.num_classes)\n","\n","        mask_data_train, mask_data_test = get_mask(path_field_class, path_mask_class)\n","        fields_coord_train, _ = get_fields_coord(mask_data_train.copy(), path_field_class, image_size, False)\n","        fields_coord_test, _ = get_fields_coord(mask_data_test.copy(), path_field_class, image_size, False)\n","        self.train_dataset = ForestDatasetPart(data_path, mask_data_train.copy(), fields_coord_train, tozero=tozero)\n","        self.test_dataset = ForestDatasetPart(data_path, mask_data_test.copy(), fields_coord_test, tozero=tozero)\n","\n","\n","\n","        self.batch_size = batch_size\n","        self.optimizer = optimizer\n","        self.scheduler = scheduler\n","        self.lr = lr\n","        self.eps = 1e-7\n","\n","        # Visualization\n","        self.color_map = torch.FloatTensor(\n","            [[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1],\n","             [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]])\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","    def training_step(self, batch, batch_idx):\n","        img, mask = batch\n","        pred = self.forward(img)\n","\n","        train_loss = F.cross_entropy(pred, mask)\n","\n","        self.log('train_loss', train_loss, prog_bar=True)\n","\n","        return train_loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        img, mask = batch\n","        pred = self.forward(img)\n","\n","        val_loss = F.cross_entropy(pred, mask) \n","        self.log('val_loss', val_loss, prog_bar=True)\n","\n","        intersection, union, target = calc_val_data(pred, mask, self.num_classes)\n","\n","        return {'intersection': intersection, 'union': union, 'target': target, 'img': img, 'pred': pred, 'mask': mask}\n","\n","    def validation_epoch_end(self, outputs):\n","        intersection = torch.cat([x['intersection'] for x in outputs])\n","        union = torch.cat([x['union'] for x in outputs])\n","        target = torch.cat([x['target'] for x in outputs])\n","\n","        mean_iou, mean_class_rec, mean_acc = calc_val_loss(intersection, union, target, self.eps)\n","\n","        log_dict = {'mean_iou': mean_iou, 'mean_class_rec': mean_class_rec, 'mean_acc': mean_acc}\n","\n","        for k, v in log_dict.items():\n","            self.log(k, v, prog_bar=True)\n","\n","    def visualize_mask(self, mask):\n","        b, h, w = mask.shape\n","        mask_ = mask.view(-1)\n","\n","        if self.color_map.device != mask.device:\n","            self.color_map = self.color_map.to(mask.device)\n","\n","        mask_vis = self.color_map[mask_].view(b, h, w, 14).permute(0, 3, 1, 2).clone()\n","\n","        return mask_vis\n","\n","    def configure_optimizers(self):\n","        opt = torch.optim.Adam(self.net.parameters(), lr=self.lr, weight_decay=0.00001)\n","        sch = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.1)\n","        return [opt], [sch]\n","\n","    def train_dataloader(self):\n","        return DataLoader(self.train_dataset, num_workers=2, batch_size=self.batch_size, shuffle=True)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.test_dataset, num_workers=2, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJErNiUWBq5u"},"outputs":[],"source":["def define_model(model_name: str,\n","                 backbone: str,\n","                 aspp: bool,\n","                 augment_data: bool,\n","                 optimizer: str,\n","                 scheduler: str,\n","                 lr: float,\n","                 data_path: str,\n","                 path_field_class: str,\n","                 path_mask_class: str,\n","                 assignment_dir: str,\n","                 batch_size: int,\n","                 num_classes: int,\n","                 num_channels: int,\n","                 image_size: int,\n","                 tozero: bool,\n","                 checkpoint_name: str = ''):\n","    experiment_name = f'{model_name}_{backbone}_augment={augment_data}_aspp={aspp}_tozero={tozero}'\n","    model_name = model_name.lower()\n","    backbone = backbone.lower() if backbone is not None else backbone\n","    \n","    model = SegModel(\n","        model_name, \n","        backbone, \n","        aspp, \n","        augment_data,\n","        optimizer,\n","        scheduler,\n","        lr,\n","        batch_size,\n","        data_path,\n","        path_field_class,\n","        path_mask_class,\n","        image_size,\n","        num_classes,\n","        num_channels,\n","        tozero)\n","\n","    if checkpoint_name:\n","        model.load_state_dict(torch.load(f'{assignment_dir}/logs/{experiment_name}/{checkpoint_name}')['state_dict'])\n","    \n","    return model, experiment_name\n","\n","def train(model, experiment_name, assignment_dir, use_gpu):\n","    logger = pl.loggers.TensorBoardLogger(save_dir=f'{assignment_dir}/logs', name=experiment_name)\n","\n","    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","        monitor='mean_iou',\n","        dirpath=f'{assignment_dir}/logs/{experiment_name}',\n","        filename='{epoch:02d}-{mean_iou:.3f}',\n","        mode='max')\n","    \n","    trainer = pl.Trainer(\n","        max_epochs=100, \n","        gpus=1 if use_gpu else None, \n","        benchmark=True, \n","        check_val_every_n_epoch=5, \n","        logger=logger, \n","        callbacks=[checkpoint_callback])\n","\n","    time_start = time.time()\n","    \n","    trainer.fit(model)\n","    \n","    torch.cuda.synchronize()\n","    time_end = time.time()\n","    \n","    training_time = (time_end - time_start) / 60\n","    \n","    return training_time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57RptrLgDBfv"},"outputs":[],"source":["with open(path_masks) as f:\n","    gj = geojson.load(f)\n","features_ind = [feature[\"properties\"][\"t_Class\"] for feature in gj['features']]\n","\n","field = np.array(gdal.Open(path_min_cloud).ReadAsArray())\n","\n","n_classes = len(np.unique(features_ind))\n","n_channels = field.shape[0]\n","\n","assignment_dir = '/Forest/dl'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXjdwKHnBq8e"},"outputs":[],"source":["model, experiment_name = define_model(\n","    model_name='UNet', #deeplab\n","    backbone=None,\n","    aspp=None,\n","    augment_data=False,\n","    optimizer='Adam',\n","    scheduler='StepLR',\n","    lr=0.001,\n","    data_path=path_snapshots,\n","    path_field_class=path_min_cloud,\n","    path_mask_class=path_masks,\n","    assignment_dir=assignment_dir,\n","    batch_size=16,\n","    num_classes=n_classes+1,\n","    num_channels=n_channels,\n","    image_size=96,\n","    tozero=True)"]},{"cell_type":"code","source":["training_time = train(model, experiment_name, assignment_dir, use_gpu=True)\n","\n","print(f'Training time: {training_time:.3f} minutes')"],"metadata":{"id":"YP3rZ3zeMIfH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6caT-GqTRbYE"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}